{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc508d0d",
   "metadata": {},
   "source": [
    "# Data Cleaning Jupyter Notebook\n",
    "## Objectives\n",
    "- Evaluate missing data\n",
    "- Clean data\n",
    "\n",
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f8b938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import ppscore as pps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1696c3f1",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472724d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"outputs/merged_data.csv\"\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b53fd23",
   "metadata": {},
   "source": [
    "### Change \"Store\" and \"Dept\" to object (categorical) and \"Date\" to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e879cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Store'] = df['Store'].astype('object')\n",
    "df['Dept'] = df['Dept'].astype('object')\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c16ffc4",
   "metadata": {},
   "source": [
    "### Dropping rows where \"Weekly_Sales\" is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2277a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Weekly_Sales'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0c1c65",
   "metadata": {},
   "source": [
    "### Data Exploration - Show columns with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98920a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values per column:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd992e18",
   "metadata": {},
   "source": [
    "### Visualize missing values using a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb903cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df.isnull(), cbar=False, cmap='viridis')\n",
    "plt.title('Missing Values Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd752a1a",
   "metadata": {},
   "source": [
    "### Correlation and Power Predictive Score (PPS) Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efec699b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_corr(df, threshold, figsize=(20, 12), font_annot=8):\n",
    "    if len(df.columns) > 1:\n",
    "        mask = np.zeros_like(df, dtype=np.bool)\n",
    "        mask[np.triu_indices_from(mask)] = True\n",
    "        mask[abs(df) < threshold] = True\n",
    "\n",
    "        fig, axes = plt.subplots(figsize=figsize)\n",
    "        sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
    "                    mask=mask, cmap='viridis', annot_kws={\"size\": font_annot}, ax=axes,\n",
    "                    linewidth=0.5\n",
    "                    )\n",
    "        axes.set_yticklabels(df.columns, rotation=0)\n",
    "        plt.ylim(len(df.columns), 0)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def heatmap_pps(df, threshold, figsize=(20, 12), font_annot=8):\n",
    "    if len(df.columns) > 1:\n",
    "\n",
    "        mask = np.zeros_like(df, dtype=np.bool)\n",
    "        mask[abs(df) < threshold] = True\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        ax = sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
    "                         mask=mask, cmap='rocket_r', annot_kws={\"size\": font_annot},\n",
    "                         linewidth=0.05, linecolor='grey')\n",
    "\n",
    "        plt.ylim(len(df.columns), 0)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def CalculateCorrAndPPS(df):\n",
    "    df_corr_spearman = df.corr(method=\"spearman\")\n",
    "    df_corr_pearson = df.corr(method=\"pearson\")\n",
    "\n",
    "    pps_matrix_raw = pps.matrix(df)\n",
    "    pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(\n",
    "        columns='x', index='y', values='ppscore')\n",
    "\n",
    "    pps_score_stats = pps_matrix_raw.query(\n",
    "        \"ppscore < 1\").filter(['ppscore']).describe().T\n",
    "    print(\"PPS threshold - check PPS score IQR to decide threshold for heatmap \\n\")\n",
    "    print(pps_score_stats.round(3))\n",
    "\n",
    "    return df_corr_pearson, df_corr_spearman, pps_matrix\n",
    "\n",
    "\n",
    "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix, CorrThreshold, PPS_Threshold,\n",
    "                      figsize=(20, 12), font_annot=8):\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"* Analyse how the target variable for your ML models are correlated with other variables (features and target)\")\n",
    "    print(\"* Analyse multi collinearity, that is, how the features are correlated among themselves\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"*** Heatmap: Spearman Correlation ***\")\n",
    "    print(\"It evaluates monotonic relationship \\n\")\n",
    "    heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold,\n",
    "                 figsize=figsize, font_annot=font_annot)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"*** Heatmap: Pearson Correlation ***\")\n",
    "    print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
    "    heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold,\n",
    "                 figsize=figsize, font_annot=font_annot)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"*** Heatmap: Power Predictive Score (PPS) ***\")\n",
    "    print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
    "          f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
    "    heatmap_pps(df=pps_matrix, threshold=PPS_Threshold,\n",
    "                figsize=figsize, font_annot=font_annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef45614",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f34f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DisplayCorrAndPPS(df_corr_pearson=df_corr_pearson,\n",
    "                  df_corr_spearman=df_corr_spearman,\n",
    "                  pps_matrix=pps_matrix,\n",
    "                  CorrThreshold=0.05, PPS_Threshold=0.1,\n",
    "                  figsize=(20, 15), font_annot=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2a9105",
   "metadata": {},
   "source": [
    "### Data Cleaning - Assessing Missing Data Levels\n",
    "Calculating missing percentage for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84593b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percentage = df.isnull().mean() * 100\n",
    "print(\"Missing Percentage per Column:\\n\", missing_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b644321f",
   "metadata": {},
   "source": [
    "### Dealing with Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c39a0a",
   "metadata": {},
   "source": [
    "### Impute 0 for missing/negative \"Weekly_Sales\" and all 5 MarkDowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23dbf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Weekly_Sales'] = df['Weekly_Sales'].apply(lambda x: x if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9281007",
   "metadata": {},
   "outputs": [],
   "source": [
    "for markdown in ['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']:\n",
    "    df[markdown] = df[markdown].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb951fd8",
   "metadata": {},
   "source": [
    "### Impute median for missing \"Temperature\", \"Fuel_Price\", \"CPI\", \"Unemployment\", \"Size\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344a3450",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'Size']:\n",
    "    median_value = df[col].median()\n",
    "    df[col] = df[col].fillna(median_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c6c78f",
   "metadata": {},
   "source": [
    "### Impute Most frequent level for missing \"Type\" and \"IsHoliday\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72ad9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Type'] = df['Type'].fillna(df['Type'].mode()[0])\n",
    "df['IsHoliday'] = df['IsHoliday'].fillna(df['IsHoliday'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003f5692",
   "metadata": {},
   "source": [
    "### Impute 46 for missing \"Store\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7062b009",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Store'] = df['Store'].fillna('46')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d44aef",
   "metadata": {},
   "source": [
    "### Impute 100 for missing \"Dept\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844746e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Dept'] = df['Dept'].fillna('100')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48622f5a",
   "metadata": {},
   "source": [
    "### Push the cleaned data to Repo (outputs folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7529f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Store'] = df['Store'].astype('object')\n",
    "df['Dept'] = df['Dept'].astype('object')\n",
    "output_path = \"outputs/Cleaned.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Cleaned data saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
